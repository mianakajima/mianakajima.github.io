<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.2">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2022-09-15T17:44:50-07:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Mia Nakajima</title><author><name>Mia Nakajima</name><email>mb.nakajima@gmail.com</email></author><entry><title type="html">Tips and Tricks for Working with Satellite Imagery</title><link href="http://localhost:4000/2022/09/15/TipsTricksSatelliteImagery/" rel="alternate" type="text/html" title="Tips and Tricks for Working with Satellite Imagery" /><published>2022-09-15T00:00:00-07:00</published><updated>2022-09-15T00:00:00-07:00</updated><id>http://localhost:4000/2022/09/15/TipsTricksSatelliteImagery</id><content type="html" xml:base="http://localhost:4000/2022/09/15/TipsTricksSatelliteImagery/"><![CDATA[<p>I am currently working with Google Earth Engine to do machine learning with satellite imagery. 
These are a couple of things I learned/wish I had known before pressing run on my code. 😅</p>

<h2 id="1-exporting-and-aligning-images---crs-and-crstransform">1. Exporting and aligning images - <code class="language-plaintext highlighter-rouge">crs</code> and <code class="language-plaintext highlighter-rouge">crsTransform</code></h2>

<p>When using Google Earth Engine’s Python API, you can export your satellite imagery to your Google Drive using <a href="https://developers.google.com/earth-engine/apidocs/export-image-todrive"><code class="language-plaintext highlighter-rouge">Export.image.toDrive()</code></a>.</p>

<p>With the function, you can specify the image you want to download, as well as the region, size, and dimensions you want to download the image at. At a cursory glance, you may think that specifying the <code class="language-plaintext highlighter-rouge">region</code> (coordinates representing region to export) and <code class="language-plaintext highlighter-rouge">scale</code> (resolution in meters per pixel) arguments are enough to download an image. 
I initially did this and ignored the <code class="language-plaintext highlighter-rouge">crs</code> and <code class="language-plaintext highlighter-rouge">crsTransform</code> arguments. 
This is true, <em>only</em> if you are only looking at one image collections.</p>

<p>If you want to compare two image collections, chances are the way their pixels are exported with respect to longitude and latitude will differ from each other. 
If you download images from these two image collections, each pixel will correspond to slightly different longitude and latitude values, even over the same region and scale.</p>

<p>The way an image collection organizes their pixels are shown by the <code class="language-plaintext highlighter-rouge">crs</code> and <code class="language-plaintext highlighter-rouge">transform</code> attributes. To get these attributes, for example for an image collection, <code class="language-plaintext highlighter-rouge">night_lights</code>, you can use <code class="language-plaintext highlighter-rouge">night_lights.projection().getInfo()</code>. This function returns this:</p>

<p><code class="language-plaintext highlighter-rouge">{'type': 'Projection', 'crs': 'EPSG:4326', 'transform': [1, 0, 0, 0, 1, 0]}</code></p>

<p>The <code class="language-plaintext highlighter-rouge">crs</code> is the <a href="https://en.wikipedia.org/wiki/Spatial_reference_system">Coordinate Reference System</a> and the <code class="language-plaintext highlighter-rouge">transform</code> refers to the transformation used to export the image. The numbers in the list represent [xScale, xShearing, xTranslation, yShearing, yScale, yTranslation] as shown in the documentation <a href="https://developers.google.com/earth-engine/guides/exporting">here</a>.</p>

<p>By choosing one <code class="language-plaintext highlighter-rouge">crs</code> and <code class="language-plaintext highlighter-rouge">transform</code> to use for all your image collection, you can export images that share the same longitude and latitude for each pixel.</p>

<p>The code would look like this:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">ee</span> 

<span class="n">start_date</span> <span class="o">=</span> <span class="s">'2020-01-01'</span>
<span class="n">end_date</span> <span class="o">=</span> <span class="s">'2020-12-31'</span>

<span class="c1"># night light data - get median image for year
</span><span class="n">night_light_2020</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="n">ImageCollection</span><span class="p">(</span><span class="s">"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG"</span><span class="p">).</span><span class="n">filterDate</span><span class="p">(</span><span class="n">start_date</span><span class="p">,</span> <span class="n">end_date</span><span class="p">).</span><span class="n">select</span><span class="p">(</span><span class="s">'avg_rad'</span><span class="p">).</span><span class="n">median</span><span class="p">()</span>

<span class="c1"># census data
</span><span class="n">census_2020</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="n">ImageCollection</span><span class="p">(</span><span class="s">"CIESIN/GPWv411/GPW_Population_Count"</span><span class="p">).</span><span class="n">filterDate</span><span class="p">(</span><span class="n">start_date</span><span class="p">,</span> <span class="n">end_date</span><span class="p">).</span><span class="n">first</span><span class="p">()</span>

<span class="c1"># get crs and crsTransform for the census data 
</span><span class="n">crs_census</span> <span class="o">=</span> <span class="n">census_2020</span><span class="p">.</span><span class="n">projection</span><span class="p">().</span><span class="n">getInfo</span><span class="p">()[</span><span class="s">'crs'</span><span class="p">]</span>
<span class="n">transform_census</span> <span class="o">=</span> <span class="n">census_2020</span><span class="p">.</span><span class="n">projection</span><span class="p">().</span><span class="n">getInfo</span><span class="p">()[</span><span class="s">'transform'</span><span class="p">]</span>

<span class="c1"># specify region
</span><span class="n">region</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="n">Geometry</span><span class="p">.</span><span class="n">BBox</span><span class="p">(</span><span class="mf">135.9259</span><span class="p">,</span> <span class="mf">35.4698</span><span class="p">,</span> <span class="mf">140.8698</span> <span class="p">,</span> <span class="mf">36.6422</span><span class="p">)</span>

<span class="c1"># export census image using census crs and transform 
</span><span class="n">task</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="n">batch</span><span class="p">.</span><span class="n">Export</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">toDrive</span><span class="p">(</span><span class="n">image</span> <span class="o">=</span> <span class="n">census_2020</span><span class="p">,</span>
                                     <span class="n">fileNamePrefix</span> <span class="o">=</span> <span class="s">'censusexport'</span><span class="p">,</span>
                                     <span class="n">region</span> <span class="o">=</span> <span class="n">region</span><span class="p">,</span>
                                     <span class="n">crsTransform</span><span class="o">=</span><span class="n">transform_census</span><span class="p">,</span>
                                     <span class="n">crs</span> <span class="o">=</span> <span class="n">crs_census</span><span class="p">)</span>

<span class="n">task</span><span class="p">.</span><span class="n">start</span><span class="p">()</span>

<span class="c1"># export night light image using census crs and transform to match lon/lat
</span><span class="n">task</span> <span class="o">=</span> <span class="n">ee</span><span class="p">.</span><span class="n">batch</span><span class="p">.</span><span class="n">Export</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">toDrive</span><span class="p">(</span><span class="n">image</span> <span class="o">=</span> <span class="n">night_light_2020</span><span class="p">,</span>
                                     <span class="n">fileNamePrefix</span> <span class="o">=</span> <span class="s">'nightlightexport'</span><span class="p">,</span>
                                     <span class="n">region</span> <span class="o">=</span> <span class="n">region</span><span class="p">,</span>
                                     <span class="n">crsTransform</span><span class="o">=</span><span class="n">transform_census</span><span class="p">,</span>
                                     <span class="n">crs</span> <span class="o">=</span> <span class="n">crs_census</span><span class="p">)</span>

<span class="n">task</span><span class="p">.</span><span class="n">start</span><span class="p">()</span></code></pre></figure>

<h2 id="2-you-might-not-have-to-download-or-export-the-image">2. You might not have to download or export the image…</h2>

<p>If you don’t actually need an image and just need a numpy array of the image values (which may be the case if you are doing machine learning), you can use the <code class="language-plaintext highlighter-rouge">geemap</code> package.</p>

<p>The <code class="language-plaintext highlighter-rouge">geemap</code> package has a function <a href="https://geemap.org/common/?h=ee_to_numpy#geemap.common.ee_to_geopandas"><code class="language-plaintext highlighter-rouge">ee_to_numpy()</code></a> which can be used to turn a Google Earth Engine image region into a numpy array. 
The caveat is that it doesn’t seem to include the <code class="language-plaintext highlighter-rouge">crs</code> or <code class="language-plaintext highlighter-rouge">crsTransform</code> arguments we talked about above so this may be exclusive if you are just working with one image collection.</p>

<h2 id="3-how-to-display-your-geotiff">3. How to display your GeoTIFF</h2>

<p>I found that there are many ways you can show a GeoTIFF image - there are many packages out there, and you can also convert the image into a different datatype to plot it through <code class="language-plaintext highlighter-rouge">matplotlib</code> or <code class="language-plaintext highlighter-rouge">plotly</code>. 
Here are the easiest ways I found to plot different types of GeoTIFF images.</p>

<h3 id="if-you-just-have-one-bandgray-scale-image">If you just have one band/gray-scale image:</h3>

<p>The easiest way I found was to use <code class="language-plaintext highlighter-rouge">rioxarray</code>. With <code class="language-plaintext highlighter-rouge">rioxarray</code>, plotting an image is as easy as two lines:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">image</span> <span class="o">=</span> <span class="n">rioxarray</span><span class="p">.</span><span class="n">open_rasterio</span><span class="p">(</span><span class="s">'image path'</span><span class="p">)</span>
<span class="n">im</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">cmap</span><span class="o">=</span><span class="s">'gray'</span><span class="p">)</span></code></pre></figure>

<p><img src="/assets/tipstricksSI/img.png" /></p>

<h3 id="if-you-have-an-rgb-image">If you have an RGB image:</h3>

<p>I found the <a href="https://earthpy.readthedocs.io/en/latest/"><code class="language-plaintext highlighter-rouge">earthpy</code></a> and <code class="language-plaintext highlighter-rouge">xarray</code> package to be helpful.</p>

<p>First, we need to create an <code class="language-plaintext highlighter-rouge">xarray</code> object of all the bands that we want to plot.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">rioxarray</span>

<span class="n">tiff</span> <span class="o">=</span> <span class="n">rioxarray</span><span class="p">.</span><span class="n">open_rasterio</span><span class="p">(</span><span class="s">'../data/test_japan_landsat.tif'</span><span class="p">)</span>
<span class="n">tiff_ds</span> <span class="o">=</span> <span class="n">tiff</span><span class="p">.</span><span class="n">to_dataset</span><span class="p">(</span><span class="s">'band'</span><span class="p">)</span>
<span class="c1"># rename bands
</span><span class="n">tiff_ds</span> <span class="o">=</span> <span class="n">tiff_ds</span><span class="p">.</span><span class="n">rename</span><span class="p">({</span><span class="mi">1</span><span class="p">:</span> <span class="s">'B1'</span><span class="p">,</span>
                          <span class="mi">2</span><span class="p">:</span> <span class="s">'B2'</span><span class="p">,</span>
                          <span class="mi">3</span><span class="p">:</span> <span class="s">'B3'</span><span class="p">,</span>
                          <span class="mi">4</span><span class="p">:</span> <span class="s">'B4'</span><span class="p">,</span>
                          <span class="mi">5</span><span class="p">:</span> <span class="s">'B5'</span><span class="p">,</span>
                          <span class="mi">6</span><span class="p">:</span> <span class="s">'B6_VCID_1'</span><span class="p">,</span>
                          <span class="mi">7</span><span class="p">:</span> <span class="s">'B6_VCID_2'</span><span class="p">,</span>
                          <span class="mi">8</span><span class="p">:</span> <span class="s">'B7'</span><span class="p">,</span>
                          <span class="mi">9</span><span class="p">:</span> <span class="s">'B8'</span><span class="p">})</span>
<span class="n">tiff_ds</span></code></pre></figure>

<p>This creates an <code class="language-plaintext highlighter-rouge">xarray</code> Dataset that looks like this:</p>

<p><img src="/assets/tipstricksSI/xarray_output.png" alt="img.png" /></p>

<p>Now, choose the bands we want to plot in RGB order using <code class="language-plaintext highlighter-rouge">xarray</code>:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">xarray</span> <span class="k">as</span> <span class="n">xr</span>

<span class="c1"># for landsat, B3 = R, B2 = G, B1 = B
</span><span class="n">rgb_bands</span> <span class="o">=</span> <span class="p">[</span><span class="n">tiff_ds</span><span class="p">.</span><span class="n">B3</span><span class="p">,</span> <span class="n">tiff_ds</span><span class="p">.</span><span class="n">B2</span><span class="p">,</span> <span class="n">tiff_ds</span><span class="p">.</span><span class="n">B1</span><span class="p">]</span>
<span class="c1"># turn rgb bands into xarray object
</span><span class="n">landsat_rgb</span> <span class="o">=</span> <span class="n">xr</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">rgb_bands</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="s">"band"</span><span class="p">)</span></code></pre></figure>

<p>And now, we can use the <code class="language-plaintext highlighter-rouge">earthpy</code> package:</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">earthpy.plot</span> <span class="k">as</span> <span class="n">ep</span>
<span class="n">ep</span><span class="p">.</span><span class="n">plot_rgb</span><span class="p">(</span><span class="n">landsat_rgb</span><span class="p">.</span><span class="n">values</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/tipstricksSI/earthpy1.png" alt="img.png" /></p>

<p>This image looks very dark! We can explore this image using <code class="language-plaintext highlighter-rouge">ep.hist()</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">ep</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">landsat_rgb</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">title</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Band 3"</span><span class="p">,</span> <span class="s">"Band 2"</span><span class="p">,</span> <span class="s">"Band 1"</span><span class="p">])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p><img src="/assets/tipstricksSI/hist.png" alt="img.png" /></p>

<p>We can see that the values are very low since image values can take on values between 0 and 255.</p>

<p>In order to be able to see the image better, we can use the <code class="language-plaintext highlighter-rouge">stretch</code> argument in <code class="language-plaintext highlighter-rouge">ep.plot_rgb()</code>.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">earthpy.plot</span> <span class="k">as</span> <span class="n">ep</span>
<span class="n">ep</span><span class="p">.</span><span class="n">plot_rgb</span><span class="p">(</span><span class="n">landsat_rgb</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">stretch</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span></code></pre></figure>

<p>We get the following image, that we are now able to see much better!</p>

<p><img src="/assets/tipstricksSI/img_stretch.png" alt="img.png" /></p>]]></content><author><name>Mia Nakajima</name><email>mb.nakajima@gmail.com</email></author><summary type="html"><![CDATA[I am currently working with Google Earth Engine to do machine learning with satellite imagery. These are a couple of things I learned/wish I had known before pressing run on my code. 😅]]></summary></entry><entry><title type="html">Stochastic Optimization of Electric Grid Forecasts</title><link href="http://localhost:4000/2022/07/22/QuadraticProgramming/" rel="alternate" type="text/html" title="Stochastic Optimization of Electric Grid Forecasts" /><published>2022-07-22T00:00:00-07:00</published><updated>2022-07-22T00:00:00-07:00</updated><id>http://localhost:4000/2022/07/22/QuadraticProgramming</id><content type="html" xml:base="http://localhost:4000/2022/07/22/QuadraticProgramming/"><![CDATA[<p>I am currently trying to reproduce a paper “Task-based End-to-end Model Learning in Stochastic Optimization” by Priya Donti, Brandon Amos and J. Zico Kolter.
In this paper, they propose a method to learn to predict something, taking into account the end task that the prediction would be used for.</p>

<p>This wouldn’t be necessary if we could predict what we’re trying to predict perfectly, but we know that’s not always the case ;) Since our model won’t be perfect, we want to make sure that the model performs well in the task it will be used for.</p>

<p>For example, the authors ran an experiment using this method on electric grid scheduling. I summarize how the electric grid scheduling is broken down using this method in the table below. The “Experiment” column shows the prediction and task associated with electric grid scheduling, while the “Method” column shows how we would find the solution to each experiment part.</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Experiment</th>
      <th>Method</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Prediction</td>
      <td>Electric load</td>
      <td>Neural network/Probabilistic Model</td>
    </tr>
    <tr>
      <td>Task</td>
      <td>Minimize the cost of a certain generator schedule (ie., both overgenerating and underegenerating electricity can incur extra costs when operating the grid)</td>
      <td>Stochastic Optimization</td>
    </tr>
  </tbody>
</table>

<p>In practice, we would first generate a neural network model to predict the electric demand/how much electricity we should generate. Then, we would find tune that model using stochastic optimization, to minize the cost on the grid.</p>

<p>Today, I want to walk through the stochastic optimization part of this method since it was not straight forward and think it’s pretty cool :)</p>

<h3 id="what-is-stochastic-optimization">What is Stochastic Optimization?</h3>

<p>In optimization, we are trying to find the optimal solution to something - usually that means we are finding the minimum or maximum of a function. Stochastic optimization is not that different. Stochastic implies a component of randomness, and stochastic optimization is just that: <strong>optimization of a function which includes random variables or constraints</strong>. The randomness may be able to be described as coming from a known distribution, or sometimes it may be unknown.</p>

<p>In this paper’s case, the function we are trying to minimize is the cost of using a certain generator schedule. In grid scheduling, usually how much energy to generate is decided for the whole 24 hours of the next day and then adjustments are made the day of as needed. We assume there are costs associated with both undergenerating and overgenerating.</p>

<p>The paper assumes the cost function looks like this:</p>

\[\min_{z \in \mathbb{R}^{24}} \sum_{i = 1}^{24} \mathbb{E}_{y~p(y\vert x;\theta)} [\gamma_s[y_i -z_i]_+ + \gamma_e[z_i - y_i]_+ + \frac{1}{2}(z_i - y_i)^2]\]

\[s.t. \vert z_i - z_{i - 1} \vert \leq c_r \forall i\]

<p>Where:</p>
<ul>
  <li>$z_i$ : Electricity generation scheduled for every hour $i$</li>
  <li>$y_i$ : Demand, which we assume comes from a Gaussian distribution</li>
  <li>$\gamma_s$: The cost of undergenerating</li>
  <li>$\gamma_e$: The cost of overgenerating</li>
  <li>$c_r$: Ramping constant (we assume the energy generation cannot change excessively from one hour to the next)</li>
  <li>$[x]_+$ : Function meaning take the maximum of $x$ or 0.</li>
</ul>

<p>Since we don’t know actually how much demand for energy there will be and we must assume it’s a random variable, this is a stochastic optimization problem.</p>

<p>The authors of this paper solve this problem using a “stochastic gradient approach”. I understood this to mean gradient descent using the cost function above rather than standard cost functions, such as root mean square error. The specific steps are:</p>

<ol>
  <li>Say $x$ (features such as weather) and $y$ (the true demand) come from some true distribution, $D$. And we are able to create an initial model $z = f(x \vert \theta)$ that predicts the demand, $z$ from features $x$.</li>
  <li>Sample $(x, y)$ from true distrubution $D$</li>
  <li>Solve for $z$ that will minimize the above cost function using sample.</li>
  <li>Now do gradient descent. Update the parameters $\theta$ by taking derivates of the cost function.</li>
  <li>Repeat steps 2-4 for a chosen number of epochs.</li>
</ol>

<p>Now the question arises: how do we solve for the best solution of $z$? For this, we can use an approach called <a href="https://en.wikipedia.org/wiki/Sequential_quadratic_programming">sequential quadratic programming</a>.</p>

<h3 id="sequential-quadratic-programming">Sequential Quadratic Programming</h3>

<p>The solution to minimizing the cost function does not look straightforward! Here, we can try using sequential quadratic programming. The big picture is that we are using local quadratic approximations of our function in order to iteratively shimmy our estimate to the real minimum of the function.</p>

<p>We can approximate the function at our intial guess of $z^{(j)}$ using a Taylor approximation to the second degree. It looks like this:</p>

\[Define: f(z) =  \mathbb{E}_{y~p(y\vert x;\theta)} [\gamma_s[y_i -z_i]_+ + \gamma_e[z_i - y_i]_+ + \frac{1}{2}(z_i - y_i)^2]\]

\[d = z^{(j + 1)} - z^{(j)}\]

\[f \approx  \nabla f(z^{(j)})d + \frac{1}{2} d^T\nabla^2 f(z^{(j)})d\]

<p>We can now actually change our problem from finding $z$ which minimizes $f(z)$ to finding $d$ which minimizes the approximation of $f(z)$  as shown below.</p>

\[d = arg \min_{d} \frac{1}{2} d^T\nabla^2 f(z^{(j)})d + \nabla f(z^{(j)})d\]

<p>We can see this follows the form of a quadratic program which has a general form:</p>

\[arg \min_{x}  \frac{1}{2} x^TQx + P^Tx\]

<p>Where:</p>

<ul>
  <li>$Q$ is a nxn matrix and $P$ is a n-dimensional vector</li>
</ul>

<p>We want to do this because quadratic programs may be easier to solve than our initial function. Dependent on the characteristics of matrix $Q$, there are known ways to solve for the minimum of the equation. Some examples are <a href="https://en.wikipedia.org/wiki/Quadratic_programming">here</a>. This paper uses a Python package <code class="language-plaintext highlighter-rouge">qpth</code> to solve the quadratic program.</p>

<p>After solving for $d$, we can now find our new estimate $z^{(j + 1)} = z^{(j)} + d$.</p>

<p>We can iteratively solve for $z^{(j + 1)}$ until we converge, ie., until $\vert z^{(j + 1)} - z^{(j)} \vert &lt; \delta$ for some small $\delta$.</p>

<h2 id="tying-it-all-together">Tying It All Together</h2>

<p>Whew! So that was a lot of math and lots of talk on iterations.</p>

<p>This process can be summed up as follows:</p>

<ol>
  <li>In a scenario where you have a problem where you may want to assess task-based accuracy (which is a stochastic programming problem) in addition to predictive accuracy, one solution may be to train a probablistic predictive model and fine tune it based on a cost function related to your task.</li>
  <li>The fine tuning involves stochastic gradient desent of your inital model using the task-based cost function.</li>
  <li>In the electric grid scheduling case, minimizng the cost function was complex so we had to use sequential quadratic programming.</li>
</ol>

<p>And that’s it for this week! :)</p>]]></content><author><name>Mia Nakajima</name><email>mb.nakajima@gmail.com</email></author><summary type="html"><![CDATA[I am currently trying to reproduce a paper “Task-based End-to-end Model Learning in Stochastic Optimization” by Priya Donti, Brandon Amos and J. Zico Kolter. In this paper, they propose a method to learn to predict something, taking into account the end task that the prediction would be used for.]]></summary></entry><entry><title type="html">Learnings from Kaggle House Prices Competition - Part 1</title><link href="http://localhost:4000/2022/07/13/MLLearnings/" rel="alternate" type="text/html" title="Learnings from Kaggle House Prices Competition - Part 1" /><published>2022-07-13T00:00:00-07:00</published><updated>2022-07-13T00:00:00-07:00</updated><id>http://localhost:4000/2022/07/13/MLLearnings</id><content type="html" xml:base="http://localhost:4000/2022/07/13/MLLearnings/"><![CDATA[<p>I wanted to try getting familiar with sklearn’s machine learning pipeline, so I started applying it to the Kaggle House Prices Competition. The data comprised of housing prices in Ames, Iowa with 79 features. I ended up learning a lot through the whole process.</p>

<h2 id="data-exploration-and-cleaning">Data Exploration and Cleaning</h2>

<p>This was a great dataset (probably purposefully so, being a “Getting Started” competition) to practice a workflow for analyzing data since there were so many features. It definitely reminded me that I need to have the patience to observe all the data. I ended up going through a couple rounds of data cleaning.</p>

<p>To make the data cleaning workflow more streamlined in the future, I came up with this workflow:</p>

<p><strong>Steps for reviewing data</strong>:</p>

<ul>
  <li>Review data explanations if available!</li>
  <li>Review missing data
    <ul>
      <li><em>Purpose</em>: To omit columns that have too many missing values, identify data cleaning approach (ie., imputation or other)</li>
      <li>Make sure to understand why data is missing. For example, in this dataset the data is NA if the house does not have a certain feature (ie., a fence). This is valuable information and should be cleaned to represent that, and not be tossed out.</li>
    </ul>
  </li>
  <li>Visualization
    <ul>
      <li><em>Purpose</em>: This can help understand correlations between the features and dependent variable. Additionally, this can help show any quirks of the dataset.
        <ul>
          <li>Look at distribution of output variable - is it normally distributed? If not, consider transforming the variable.</li>
          <li>Make pair scatter plots of all the numeric variables.</li>
          <li>Make boxplots of categorical variables with respect to the dependent variable</li>
          <li>Any others that might be helpful</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="the-sklearn-pipeline">The sklearn pipeline</h2>

<h3 id="first-some-terminology">First, some terminology</h3>

<p>One thing I learned is that there are many words in machine learning that sound scary but are actually very simple concepts. For example, “pipeline” sounds very scary, but it’s just a fancy word to describe a way to apply a series of functions to your data, either to clean your data, transform it or model it.</p>

<p>Below are some of such words that I’ll keep be using throughout:</p>

<table>
  <thead>
    <tr>
      <th>Terminology</th>
      <th>In “English”</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Pipeline</td>
      <td>An object you can use to apply many functions to your data (for data cleaning, transforming or modeling)</td>
    </tr>
    <tr>
      <td>Transformer</td>
      <td>A function to “transform” your data, which can be as simple as scaling it</td>
    </tr>
    <tr>
      <td>Custom Transformer</td>
      <td>A function you write that can be applied to your pipeline</td>
    </tr>
    <tr>
      <td>Feature Engineering</td>
      <td>You use the variables (features) you have to come up with new ones that may be helpful. For example if you have square footage and rooms, maybe you want to know the square footage per room.</td>
    </tr>
  </tbody>
</table>

<h3 id="the-pipeline">The Pipeline</h3>
<p>Using sklearn’s pipeline was super streamlined! Below shows a code snippet of what the pipeline looks like. The <code class="language-plaintext highlighter-rouge">ColumnTransfomer()</code> function allows you to apply different pipelines to the data by the column name. In this case, I had 3 separate pipelines by the data type. Each pipeline is composed of sklearn functions or custom transformers.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="c1"># Pipeline for numeric variables
</span><span class="n">numeric_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s">'postprocess'</span><span class="p">,</span> <span class="n">CleanRemodels</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'impute'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s">'median'</span><span class="p">)),</span>
    <span class="p">(</span><span class="s">'homearea'</span><span class="p">,</span> <span class="n">add_home_area</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'scale'</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Pipeline for categorical variables
</span><span class="n">cat_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s">'postprocess'</span><span class="p">,</span> <span class="n">clean_categorical</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'onehot'</span><span class="p">,</span> <span class="n">OneHotEncoder</span><span class="p">(</span><span class="n">handle_unknown</span> <span class="o">=</span> <span class="s">'ignore'</span><span class="p">))</span>
<span class="p">])</span>

<span class="c1"># Pipeline for categorical variables that should be changed into numeric
</span><span class="n">cat_ordinal_pipeline</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">steps</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">(</span><span class="s">'postprocess'</span><span class="p">,</span> <span class="n">clean_categorical</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'impute'</span><span class="p">,</span> <span class="n">SimpleImputer</span><span class="p">(</span><span class="n">strategy</span> <span class="o">=</span> <span class="s">'most_frequent'</span><span class="p">)),</span>
    <span class="p">(</span><span class="s">'ordinal'</span><span class="p">,</span> <span class="n">change_to_ordinal</span><span class="p">()),</span>
    <span class="p">(</span><span class="s">'scale'</span><span class="p">,</span> <span class="n">MinMaxScaler</span><span class="p">())</span>
<span class="p">])</span>

<span class="c1"># Full pipeline that gets applied to data, which combines above three pipelines
# ColumnTransfomer allows different pipelines to be applied to the data by
# passing in the columns it should apply to.
</span><span class="n">full_pipeline</span> <span class="o">=</span> <span class="n">ColumnTransformer</span><span class="p">([</span>
    <span class="p">(</span><span class="s">"cat"</span><span class="p">,</span> <span class="n">cat_pipeline</span><span class="p">,</span> <span class="n">cat_columns</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"num"</span><span class="p">,</span> <span class="n">numeric_pipeline</span><span class="p">,</span> <span class="n">num_columns</span><span class="p">),</span>
    <span class="p">(</span><span class="s">"ord"</span><span class="p">,</span> <span class="n">cat_ordinal_pipeline</span><span class="p">,</span> <span class="n">ordinal_columns</span><span class="p">)</span>
<span class="p">])</span>

<span class="n">housing_prepared</span> <span class="o">=</span> <span class="n">full_pipeline</span><span class="p">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">training</span><span class="p">)</span></code></pre></figure>

<h3 id="custom-transformers">Custom Transformers</h3>

<p>A useful thing I learned is that you can create custom transfomers and add it to your pipeline. For example, I created a <code class="language-plaintext highlighter-rouge">add_home_area</code> Custom Transformer that adds the total home area to the dataset, which I decided to add for feature engineering. This is used in the numeric pipeline above.</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">add_home_area</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">TransformerMixin</span><span class="p">):</span>
    <span class="s">"""
    Function to add total home area to numeric variables
    """</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="bp">None</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">transform</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">total_area</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">sum</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">indexes</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">c_</span><span class="p">[</span><span class="n">X</span><span class="p">,</span> <span class="n">total_area</span><span class="p">]</span></code></pre></figure>]]></content><author><name>Mia Nakajima</name><email>mb.nakajima@gmail.com</email></author><summary type="html"><![CDATA[I wanted to try getting familiar with sklearn’s machine learning pipeline, so I started applying it to the Kaggle House Prices Competition. The data comprised of housing prices in Ames, Iowa with 79 features. I ended up learning a lot through the whole process.]]></summary></entry></feed>